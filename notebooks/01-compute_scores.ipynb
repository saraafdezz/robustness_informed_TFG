{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sc-best-practices.org/conditions/gsea_pathway.html#id380\n",
    "# Kang HM, Subramaniam M, Targ S, et al. Multiplexed droplet single-cell RNA-sequencing using natural genetic variation\n",
    "#   Nat Biotechnol. 2020 Nov;38(11):1356]. Nat Biotechnol. 2018;36(1):89-94. doi:10.1038/nbt.4042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_kind = \"ivae_random-0.1\"\n",
    "frac = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kind = str(model_kind)\n",
    "frac = float(frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-10 08:46:25.467149: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739177185.479926 1553794 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739177185.483800 1553794 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-10 08:46:25.499264: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/sfernandez/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.10.4 anndata==0.11.3 umap==0.5.7 numpy==1.26.4 scipy==1.15.1 pandas==2.2.3 scikit-learn==1.6.1 statsmodels==0.14.4 igraph==0.10.8 pynndescent==0.5.13\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from scipy.stats import weightedtau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from isrobust_TFG.bio import (\n",
    "    build_hipathia_renamers,\n",
    "    get_adj_matrices,\n",
    "    get_random_adj,\n",
    "    get_reactome_adj,\n",
    "    sync_gexp_adj,\n",
    ")\n",
    "from isrobust_TFG.datasets import load_kang\n",
    "from isrobust_TFG.utils import set_all_seeds\n",
    "\n",
    "project_path = Path(dotenv.find_dotenv()).parent\n",
    "\n",
    "data_path = project_path.joinpath(\"data\")\n",
    "data_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "set_all_seeds(seed=42)\n",
    "\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "sc.set_figure_params(dpi=300, color_map=\"inferno\")\n",
    "sc.settings.verbosity = 1\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('IVAE_ENV_FOLDER', './.venvs/ivae'),\n",
       "             ('BINN_ENV_FOLDER', './.venvs/binn'),\n",
       "             ('N_GPU', '3'),\n",
       "             ('N_CPU', '20'),\n",
       "             ('SEED', '42'),\n",
       "             ('SEED_START', '0'),\n",
       "             ('SEED_STOP', '50'),\n",
       "             ('SEED_STEP', '1'),\n",
       "             ('DEBUG', '1'),\n",
       "             ('FRAC_START', '0.05'),\n",
       "             ('FRAC_STOP', '0.85'),\n",
       "             ('FRAC_STEP', '0.2'),\n",
       "             ('RESULTS_FOLDER', 'path')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dotenv.dotenv_values()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = bool(int(config[\"DEBUG\"]))\n",
    "\n",
    "results_path = Path(config[\"RESULTS_FOLDER\"])\n",
    "results_path.mkdir(exist_ok=True, parents=True)\n",
    "figs_path = results_path.joinpath(\"figs\")\n",
    "figs_path.mkdir(exist_ok=True, parents=True)\n",
    "tables_path = results_path.joinpath(\"tables\")\n",
    "tables_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = list(\n",
    "    range(\n",
    "        int(config[\"SEED_START\"]),\n",
    "        int(config[\"SEED_STOP\"]) + 1,\n",
    "        int(config[\"SEED_STEP\"]),\n",
    "    )\n",
    ")\n",
    "N_ITERS = len(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug=True model_kind='ivae_random-0.1'\n"
     ]
    }
   ],
   "source": [
    "if debug:\n",
    "    N_EPOCHS = 2\n",
    "else:\n",
    "    N_EPOCHS = 300\n",
    "\n",
    "if model_kind == \"ivae_kegg\":\n",
    "    n_encoding_layers = 3\n",
    "elif model_kind == \"ivae_reactome\":\n",
    "    n_encoding_layers = 2\n",
    "elif \"ivae_random\" in model_kind:\n",
    "    n_encoding_layers = 2\n",
    "else:\n",
    "    raise NotImplementedError(f\"{model_kind} not implemented yet.\")\n",
    "\n",
    "print(f\"{debug=} {model_kind=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfernandez/TFG/robustness_informed_TFG/isrobust_TFG/datasets.py:18: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  adata.obs[\"label\"] = adata.obs[\"label\"].replace(\n"
     ]
    }
   ],
   "source": [
    "if \"ivae_random\" in model_kind:\n",
    "    n_genes = 3000\n",
    "else:\n",
    "    n_genes = None\n",
    "adata = load_kang(data_folder=data_path, normalize=True, n_genes=n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trans = adata.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>circuit</th>\n",
       "      <th>P-hsa03320-62</th>\n",
       "      <th>P-hsa03320-45</th>\n",
       "      <th>P-hsa03320-43</th>\n",
       "      <th>P-hsa03320-23</th>\n",
       "      <th>P-hsa03320-32</th>\n",
       "      <th>P-hsa03320-8</th>\n",
       "      <th>P-hsa03320-7</th>\n",
       "      <th>P-hsa03320-9</th>\n",
       "      <th>P-hsa03320-39</th>\n",
       "      <th>P-hsa03320-38</th>\n",
       "      <th>...</th>\n",
       "      <th>P-hsa05164-41.42</th>\n",
       "      <th>P-hsa05164-47</th>\n",
       "      <th>P-hsa05164-53</th>\n",
       "      <th>P-hsa05164-65.66</th>\n",
       "      <th>P-hsa05164-68</th>\n",
       "      <th>P-hsa05164-70</th>\n",
       "      <th>P-hsa05164-77</th>\n",
       "      <th>P-hsa05164-78</th>\n",
       "      <th>P-hsa05164-90</th>\n",
       "      <th>P-hsa05164-99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TANK</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NR1H3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPIF</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LPAR6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDK4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "circuit  P-hsa03320-62  P-hsa03320-45  P-hsa03320-43  P-hsa03320-23  \\\n",
       "symbol                                                                \n",
       "TANK                 0              0              0              0   \n",
       "NR1H3                0              0              0              0   \n",
       "PPIF                 0              0              0              0   \n",
       "LPAR6                0              0              0              0   \n",
       "CDK4                 0              0              0              0   \n",
       "\n",
       "circuit  P-hsa03320-32  P-hsa03320-8  P-hsa03320-7  P-hsa03320-9  \\\n",
       "symbol                                                             \n",
       "TANK                 0             0             0             0   \n",
       "NR1H3                0             0             0             0   \n",
       "PPIF                 0             0             0             0   \n",
       "LPAR6                0             0             0             0   \n",
       "CDK4                 0             0             0             0   \n",
       "\n",
       "circuit  P-hsa03320-39  P-hsa03320-38  ...  P-hsa05164-41.42  P-hsa05164-47  \\\n",
       "symbol                                 ...                                    \n",
       "TANK                 0              0  ...                 0              0   \n",
       "NR1H3                0              0  ...                 0              0   \n",
       "PPIF                 0              0  ...                 0              0   \n",
       "LPAR6                0              0  ...                 0              0   \n",
       "CDK4                 0              0  ...                 0              0   \n",
       "\n",
       "circuit  P-hsa05164-53  P-hsa05164-65.66  P-hsa05164-68  P-hsa05164-70  \\\n",
       "symbol                                                                   \n",
       "TANK                 0                 0              0              0   \n",
       "NR1H3                0                 0              0              0   \n",
       "PPIF                 0                 0              0              0   \n",
       "LPAR6                0                 0              0              0   \n",
       "CDK4                 0                 0              0              0   \n",
       "\n",
       "circuit  P-hsa05164-77  P-hsa05164-78  P-hsa05164-90  P-hsa05164-99  \n",
       "symbol                                                               \n",
       "TANK                 0              0              0              0  \n",
       "NR1H3                0              0              0              0  \n",
       "PPIF                 0              0              0              0  \n",
       "LPAR6                0              0              0              0  \n",
       "CDK4                 0              0              0              0  \n",
       "\n",
       "[5 rows x 1221 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit_adj, circuit_to_pathway_adj = get_adj_matrices(\n",
    "    gene_list=x_trans.columns.to_list()\n",
    ")\n",
    "\n",
    "circuit_renamer, pathway_renamer, circuit_to_effector = build_hipathia_renamers()\n",
    "\n",
    "kegg_circuit_names = circuit_adj.rename(columns=circuit_renamer).columns\n",
    "\n",
    "kegg_pathway_names = circuit_to_pathway_adj.rename(columns=pathway_renamer).columns\n",
    "\n",
    "circuit_adj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome = get_reactome_adj()\n",
    "reactome_pathway_names = reactome.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_kind == \"ivae_kegg\":\n",
    "    x_trans, circuit_adj = sync_gexp_adj(gexp=x_trans, adj=circuit_adj)\n",
    "elif model_kind == \"ivae_reactome\":\n",
    "    x_trans, reactome = sync_gexp_adj(x_trans, reactome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.random.get_state()\n",
    "\n",
    "# we ensure to presever the same sparsity structure for a given frac across all seeds\n",
    "random_layer, random_layer_names = get_random_adj(\n",
    "    frac, shape=reactome.shape, size=reactome.size, index=reactome.index, seed=0\n",
    ")\n",
    "\n",
    "np.random.set_state(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_kind == \"ivae_kegg\":\n",
    "    x_trans, circuit_adj = sync_gexp_adj(gexp=x_trans, adj=circuit_adj)\n",
    "elif model_kind == \"ivae_reactome\":\n",
    "    x_trans, reactome = sync_gexp_adj(x_trans, reactome)\n",
    "elif \"ivae_random\" in model_kind:\n",
    "    x_trans, random_layer = sync_gexp_adj(x_trans, random_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_importances(data, abs=False):\n",
    "    if abs:\n",
    "        return np.abs(data).mean(axis=0)\n",
    "    else:\n",
    "        return data.mean(axis=0)\n",
    "\n",
    "\n",
    "def get_activations(act_model, layer_id, data):\n",
    "    data_encoded = act_model.predict(data)[layer_id]\n",
    "    return data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(features, val_size, test_size, stratify, seed):\n",
    "    train_size = 1 - (val_size + test_size)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        features,\n",
    "        stratify,\n",
    "        train_size=train_size,\n",
    "        stratify=stratify,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    x_val, x_test = train_test_split(\n",
    "        x_test,\n",
    "        test_size=test_size / (test_size + val_size),\n",
    "        stratify=y_test,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    x_train = x_train.astype(\"float32\")\n",
    "    x_val = x_val.astype(\"float32\")\n",
    "    x_test = x_test.astype(\"float32\")\n",
    "\n",
    "    return x_train, x_val, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_model = results_path.joinpath(model_kind)\n",
    "obs = adata.obs.copy()\n",
    "results_path_model.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_kind == \"ivae_kegg\":\n",
    "    # vae, encoder, decoder = build_kegg_vae(\n",
    "    #     circuits=circuit_adj, pathways=circuit_to_pathway_adj, seed=42\n",
    "    # )\n",
    "    layer_ids = [1, 2, 3]\n",
    "elif model_kind == \"ivae_reactome\":\n",
    "    # vae, encoder, decoder = build_reactome_vae(reactome, seed=42)\n",
    "    layer_ids = [1, 2]\n",
    "elif \"ivae_random\" in model_kind:\n",
    "    # vae, encoder, decoder = build_reactome_vae(random_layer, seed=42)\n",
    "    layer_ids = [1, 2]\n",
    "else:\n",
    "    raise NotImplementedError(\"Model not yet implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_layer_names = [\"split\", \"layer\", \"seed\", \"cell_type\", \"condition\", \"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('path/ivae_random-0.1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_path_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path/ivae_random-0.1/metrics-seed-00.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores_metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     pd\u001b[38;5;241m.\u001b[39mread_pickle(results_path_model\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics-seed-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m scores_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(scores_metrics, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m scores_metrics\u001b[38;5;241m.\u001b[39mto_pickle(results_path_model\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores_metrics.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m scores_metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_path_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetrics-seed-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mseed\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m02d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m scores_metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(scores_metrics, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m scores_metrics\u001b[38;5;241m.\u001b[39mto_pickle(results_path_model\u001b[38;5;241m.\u001b[39mjoinpath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores_metrics.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path/ivae_random-0.1/metrics-seed-00.pkl'"
     ]
    }
   ],
   "source": [
    "scores_metrics = [\n",
    "    pd.read_pickle(results_path_model.joinpath(f\"metrics-seed-{seed:02d}.pkl\"))\n",
    "    for seed in seeds\n",
    "]\n",
    "scores_metrics = pd.concat(scores_metrics, axis=0, ignore_index=True)\n",
    "scores_metrics.to_pickle(results_path_model.joinpath(\"scores_metrics.pkl\"))\n",
    "\n",
    "scores_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context=\"paper\", font_scale=0.5, style=\"ticks\", rc=custom_params)\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=scores_metrics,\n",
    "    kind=\"violin\",\n",
    "    col=\"metric\",\n",
    "    height=2,\n",
    "    aspect=0.9,\n",
    "    sharey=False,\n",
    "    x=\"model\",\n",
    "    y=\"score\",\n",
    "    hue=\"split\",\n",
    "    split=False,\n",
    "    cut=0,\n",
    "    fill=False,\n",
    "    density_norm=\"count\",\n",
    "    inner=\"quart\",\n",
    "    linewidth=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informed = {}\n",
    "\n",
    "for layer_id in layer_ids:\n",
    "    if results_path_model.joinpath(\n",
    "        f\"encodings_layer-{layer_id:02d}_seed-00.pkl\"\n",
    "    ).exists():\n",
    "        results_layer = [\n",
    "            pd.read_pickle(\n",
    "                results_path_model.joinpath(\n",
    "                    f\"encodings_layer-{layer_id:02d}_seed-{seed:02d}.pkl\"\n",
    "                )\n",
    "            )\n",
    "            for seed in seeds\n",
    "        ]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    scores_informed[layer_id] = {}\n",
    "    for split in [\"train\", \"test\", \"val\"]:\n",
    "        results = [\n",
    "            x.loc[x[\"split\"] == split].drop(non_layer_names, axis=1)\n",
    "            for x in results_layer\n",
    "        ]\n",
    "        scores_informed[layer_id][split] = []\n",
    "        for seed_i in seeds:\n",
    "            for seed_j in range(seed_i + 1, N_ITERS):\n",
    "                scores_informed[layer_id][split].append(\n",
    "                    weightedtau(\n",
    "                        get_importances(data=results[seed_i], abs=True),\n",
    "                        get_importances(data=results[seed_j], abs=True),\n",
    "                    )[0]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informed = (\n",
    "    pd.DataFrame.from_dict(scores_informed)\n",
    "    .melt(var_name=\"layer\", value_name=\"score\", ignore_index=False)\n",
    "    .reset_index(names=[\"split\"])\n",
    "    .explode(\"score\")\n",
    ")\n",
    "scores_informed[\"score\"] = scores_informed[\"score\"].astype(\"float\")\n",
    "scores_informed[\"model\"] = model_kind\n",
    "scores_informed.to_pickle(results_path_model.joinpath(\"scores_informed.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_model.joinpath(\"scores_informed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context=\"paper\", font_scale=0.5, style=\"ticks\", rc=custom_params)\n",
    "plt.figure(figsize=(2, 2))\n",
    "sns.violinplot(\n",
    "    data=scores_informed,\n",
    "    x=\"layer\",\n",
    "    y=\"score\",\n",
    "    hue=\"split\",\n",
    "    split=False,\n",
    "    cut=0,\n",
    "    fill=False,\n",
    "    density_norm=\"count\",\n",
    "    inner=\"quart\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "\n",
    "batch_size = 256 * cpu_count() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_scores = {}\n",
    "\n",
    "for layer_id in layer_ids:\n",
    "    if results_path_model.joinpath(\n",
    "        f\"encodings_layer-{layer_id:02d}_seed-00.pkl\"\n",
    "    ).exists():\n",
    "        results_layer = [\n",
    "            pd.read_pickle(\n",
    "                results_path_model.joinpath(\n",
    "                    f\"encodings_layer-{layer_id:02d}_seed-{seed:02d}.pkl\"\n",
    "                )\n",
    "            )\n",
    "            for seed in range(N_ITERS)\n",
    "        ]\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    train_embeddings_lst = [\n",
    "        x.loc[(x[\"split\"] == \"train\") & (x[\"condition\"] == \"control\")]\n",
    "        for x in results_layer\n",
    "    ]\n",
    "    val_embeddings_lst = [\n",
    "        x.loc[(x[\"split\"] == \"val\") & (x[\"condition\"] == \"control\")]\n",
    "        for x in results_layer\n",
    "    ]\n",
    "    test_embeddings_lst = [\n",
    "        x.loc[(x[\"split\"] == \"test\") & (x[\"condition\"] == \"control\")]\n",
    "        for x in results_layer\n",
    "    ]\n",
    "\n",
    "    clust_scores[layer_id] = {}\n",
    "    clust_scores[layer_id][\"train\"] = []\n",
    "    clust_scores[layer_id][\"val\"] = []\n",
    "    clust_scores[layer_id][\"test\"] = []\n",
    "\n",
    "    for seed in range(N_ITERS):\n",
    "        y_train = train_embeddings_lst[seed][\"cell_type\"]\n",
    "        y_val = val_embeddings_lst[seed][\"cell_type\"]\n",
    "        y_test = test_embeddings_lst[seed][\"cell_type\"]\n",
    "\n",
    "        train_embeddings = train_embeddings_lst[seed].drop(non_layer_names, axis=1)\n",
    "        val_embeddings = val_embeddings_lst[seed].drop(non_layer_names, axis=1)\n",
    "        test_embeddings = test_embeddings_lst[seed].drop(non_layer_names, axis=1)\n",
    "\n",
    "        model = MiniBatchKMeans(n_clusters=y_train.nunique(), batch_size=batch_size)\n",
    "        model.fit(train_embeddings)\n",
    "        clust_scores[layer_id][\"train\"].append(\n",
    "            adjusted_mutual_info_score(y_train, model.labels_)\n",
    "        )\n",
    "        clust_scores[layer_id][\"val\"].append(\n",
    "            adjusted_mutual_info_score(y_val, model.predict(val_embeddings))\n",
    "        )\n",
    "        clust_scores[layer_id][\"test\"].append(\n",
    "            adjusted_mutual_info_score(y_test, model.predict(test_embeddings))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_model.joinpath(\"scores_clustering.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_scores = (\n",
    "    pd.DataFrame.from_dict(clust_scores)\n",
    "    .melt(var_name=\"layer\", value_name=\"score\", ignore_index=False)\n",
    "    .reset_index(names=[\"split\"])\n",
    "    .explode(\"score\")\n",
    ")\n",
    "clust_scores[\"score\"] = clust_scores[\"score\"].astype(\"float\")\n",
    "clust_scores[\"model\"] = model_kind\n",
    "clust_scores.to_pickle(results_path_model.joinpath(\"scores_clustering.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_params = {\"axes.spines.right\": False, \"axes.spines.top\": False}\n",
    "sns.set_theme(context=\"paper\", font_scale=0.5, style=\"ticks\", rc=custom_params)\n",
    "plt.figure(figsize=(2, 2))\n",
    "sns.violinplot(\n",
    "    data=clust_scores,\n",
    "    x=\"layer\",\n",
    "    y=\"score\",\n",
    "    hue=\"split\",\n",
    "    split=False,\n",
    "    cut=0,\n",
    "    fill=False,\n",
    "    density_norm=\"count\",\n",
    "    inner=\"quart\",\n",
    "    linewidth=0.5,\n",
    ")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
